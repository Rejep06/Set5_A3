# HyperLogLog (HLL) — реализация и эксперименты (Этапы 1–2 + выбор B + графики)

## 1) Требования

### C++
- Компилятор с поддержкой C++17+ (`g++`, `clang++`, MSVC)

### Python (для графиков)
- Python 3.x
- `matplotlib` (только он; `pandas` не нужен)

---

## 2) Структура файлов (рекомендуемая)

- `main.cpp` — общий код (генераторы, HLL, режимы тестов)
- `plot.py` — построение графиков из CSV
- `graph1.csv`, `graph2.csv` — результаты (создаются программой)
- `chooseB.csv` — результаты теста выбора B (создаётся программой)

---

## 3) Сборка

### Linux / WSL
```bash
g++ -O2 -std=c++17 main.cpp -o hll
```

### Windows (MinGW)
```powershell
g++ -O2 -std=c++17 main.cpp -o hll.exe
```

---

## 4) Этап 1: инфраструктура

### 4.1 RandomStreamGen
Генерирует поток строк длиной `1..30` из алфавита:
- `A-Z`, `a-z`, `0-9`, `-`

Поток хранится в памяти (вектор строк), чтобы удобно моделировать моменты времени `t` как префиксы.

### 4.2 HashFuncGen
Хеш-функция строится как семейство k-независимых полиномов:
```
h(x) = (a0 + a1*x + ... + a{k-1}*x^{k-1}) mod M
```
где:
- `M = 4294967291` — простое число чуть меньше `2^32`,
- коэффициенты `ai` выбираются случайно (по seed).

Строка переводится в число `x ∈ [0, M)` (строковый полином по модулю `M`),
после чего применяется k-независимый полином.

---

## 5) Выбор параметра B (почему этот код правильный)

В HLL 32-битный хеш делится на две части:

- первые **B бит** → индекс регистра `j` (субпоток), всего `m = 2^B` регистров  
- оставшиеся **32−B бит** → хвост `w`, из которого вычисляется `rho(w)` (позиция первой единицы)

Задание просит выбирать B так, чтобы:
1) **элементы равномерно распределялись по субпотокам**  
2) **оставшиеся (32−B) бит распределялись корректно внутри субпотоков**  
3) итоговая оценка была точной и стабильной

Поэтому тест выбора B делает 3 проверки для каждого B:

### 5.1 Равномерность по регистраторам (первые B бит)
Считается `cnt[j]` — сколько элементов попало в регистр `j`.
Если хеш равномерный, то `cnt[j]` ≈ `N/m`.

Метрики:
- `mu = N/m` — средняя нагрузка на регистр
- `cv = stdev(cnt)/mu` — относительный разброс по регистраторам
- `min/max` — быстрый индикатор перекоса

**Зачем:** если распределение по `j` неравномерно, часть регистров переиспользуется чаще и HLL начинает давать хуже оценку.

### 5.2 Проверка “хвоста” (оставшиеся 32−B бит)
Для каждого элемента вычисляем `rho(w)` и считаем по регистрам:
- `rho_avg[j]` — среднее значение `rho` внутри регистра `j`
- `rho_sd_reg` — разброс `rho_avg[j]` между регистрами

**Зачем:** если хвостовые биты случайны и независимы от `j`, то распределение `rho` должно быть похожим во всех регистрах.
Большой `rho_sd_reg` означает корреляции/перекос (хеш или выбор битов работает плохо).

### 5.3 Проверка точности
Считаем:
- точное `F0` (через `unordered_set`)
- оценку `HLL_est`
- `rel_error = |HLL_est - F0| / F0`

### 5.4 Почему нужен порог `mu >= 20`
Если `mu = N/m` слишком маленькое (B слишком большой), многие регистры пустые.
Тогда статистика внутри регистра шумная и дисперсия HLL растёт.  
Порог `mu >= 20` — практическая эвристика (можно брать 20–50), чтобы регистры были достаточно заполнены.

В итоге `B` выбрал 9.

---

## 6) Этап 2: реализация HyperLogLog

Параметр:
- `B` — число бит индекса регистра (`m=2^B`)

Алгоритм:
1) `x = hash(s)` (32-bit)
2) `j = topBbits(x)`
3) `w = remaining bits`
4) `M[j] = max(M[j], rho(w))`
5) оценка по стандартной формуле HLL + small-range correction (LinearCounting)

---

## 7) Режимы запуска

### 7.1 Режим выбора B
Программа:
- генерирует один поток длины `N`
- вычисляет хеши
- для каждого `B` в диапазоне (например 8..16):
  - метрики равномерности (`mu`, `cv`, `min/max`)
  - метрики хвоста (`rho_mu_reg`, `rho_sd_reg`)
  - `HLL_est` и `rel_error`
- сохраняет таблицу в `chooseB.csv`
- печатает “предложенный B”

### 7.2 Режим основного эксперимента (CSV для графиков)
Программа:
- генерирует `STREAMS` потоков (разные seed)
- для каждого момента времени `t` (например 10%, 20%, …):
  - точное `F0^t`
  - оценку `N_t`
- сохраняет:
  - `graph1.csv` (для одного потока)
  - `graph2.csv` (mean ± stdev по всем потокам)

---

## 8) CSV-форматы

### graph1.csv
- `prefix_len, exact, estimate`

### graph2.csv
- `prefix_len, mean_est, std_est, upper, lower`
- `upper = mean_est + std_est`
- `lower = mean_est - std_est`

---

## 9) Построение графиков (Python)

### 9.1 Установка matplotlib (если есть интернет)
```bash
python -m pip install matplotlib
```

Если pip недоступен (WSL/ограничения сети), можно:
- построить графики в Excel по CSV, или
- установить `python3-matplotlib` через `apt` (Linux/WSL).

### 9.2 Запуск
В папке с `graph1.csv` и `graph2.csv`:
```bash
python graph.py
```

Результат:
- `graph1.png`
- `graph2.png`

---



# Этап 3. Анализ результатов стандартного HyperLogLog (B = 9)

Ниже приведён анализ практических результатов работы HyperLogLog и сравнение с теоретическими оценками.  
Используются файлы:

- `graph1.csv`: `prefix_len, exact, estimate` (один поток)
- `graph2.csv`: `prefix_len, mean_est, std_est, upper, lower` (статистика по нескольким потокам)

Параметр алгоритма: **B = 9**, значит число регистров:

- \( m = 2^B = 2^9 = 512 \)

---

## 1) Точность и сравнение с теорией (1.04/√m и 1.32/√m)

Теоретическая относительная стандартная ошибка (RSE) HyperLogLog:

\[
RSE_{\text{theory}} \approx \frac{1.04}{\sqrt{m}}
\]

и более консервативная оценка:

\[
RSE_{\text{cons}} \approx \frac{1.32}{\sqrt{m}}
\]

Для \(m=512\):

- \(\sqrt{512} \approx 22.627\)
- \(\frac{1.04}{\sqrt{512}} \approx 0.04596\) (≈ **4.60%**)
- \(\frac{1.32}{\sqrt{512}} \approx 0.05834\) (≈ **5.83%**)

### Практическая оценка RSE

По `graph2.csv` у нас есть стандартное отклонение оценок \( \sigma(N_t) \) (`std_est`) и точное значение \(F_0^t\) (`exact` из `graph1.csv`).  
Практическую относительную стандартную ошибку считаем как:

\[
\widehat{RSE}(t) = \frac{\sigma(N_t)}{F_0^t} = \frac{std\_est(t)}{exact(t)}
\]

Результаты (по данным):

| prefix_len | exact | std_est | RSE_hat = std_est / exact |
|---:|---:|---:|---:|
| 30000  | 28948  | 1299.08  | 0.0449 |
| 60000  | 57653  | 2644.31  | 0.0459 |
| 90000  | 86209  | 4510.49  | 0.0523 |
| 120000 | 114603 | 5708.27  | 0.0498 |
| 150000 | 142817 | 7387.09  | 0.0517 |
| 180000 | 171051 | 7590.17  | 0.0444 |
| 210000 | 199229 | 8855.20  | 0.0444 |
| 239999 | 227357 | 9230.92  | 0.0406 |
| 270000 | 255463 | 11027.6  | 0.0432 |
| 300000 | 283524 | 12425.3  | 0.0438 |

Статистика по всем точкам:
- Среднее значение \(\widehat{RSE}\) ≈ **0.0459**
- Минимум ≈ **0.0406**
- Максимум ≈ **0.0523**

### Вывод по точности

- Средняя практическая \(\widehat{RSE}\) (**≈ 0.0459**) практически совпадает с теоретической \(\frac{1.04}{\sqrt{512}}\) (**≈ 0.0460**).
- Во всех моментах времени \(\widehat{RSE}(t)\) **не превышает** \(\frac{1.32}{\sqrt{512}}\) (**≈ 0.0583**).
- Небольшие колебания вокруг теоретической линии (например, рост до ~0.052 на некоторых t) являются нормальными для конечного числа запусков/потоков и переходных режимов.

Итого: **практическая точность соответствует теории** и укладывается в рамки оценок \(1.04/\sqrt{m}\) и \(1.32/\sqrt{m}\).

---

## 2) Стабильность оценки (дисперсия)

Стабильность характеризуется дисперсией/стандартным отклонением оценок \(N_t\) между разными потоками:

- абсолютное \(\sigma(N_t)\) (`std_est`) растёт с ростом количества уникальных элементов (что естественно),
- при этом относительный разброс \(\sigma(N_t)/F_0^t\) держится примерно на уровне **4–5%** и стабилизируется около величины \(\approx 1.04/\sqrt{m}\).

Это означает, что оценка **стабильна** и её разброс хорошо соответствует теоретической модели HLL для \(m=512\).

---

## 3) Эффективность констант и влияние параметров

### 3.1 Влияние B (числа регистров m=2^B)
Параметр `B` задаёт компромисс:

- увеличение `B` -> увеличение `m` -> снижение теоретической ошибки как \( \sim 1/\sqrt{m} \),
- но увеличение `m` увеличивает память и при фиксированном размере потока уменьшает среднее число элементов на регистр \( \mu = N/m \), что может увеличивать шум при слишком больших `B`.

В данном эксперименте при **B=9**:
- \(m=512\),
- теоретическая RSE ≈ 4.6%,
- практическая RSE ≈ 4.6% (почти совпало).

Это говорит, что `B=9` даёт корректный баланс точности и устойчивости для выбранных размеров потоков.

### 3.2 Константа αm (нормировка HyperLogLog)
В стандартном HLL используется коэффициент \(\alpha_m\) (зависит от m).  
Он влияет на **смещение** оценки (bias). Корректный выбор \(\alpha_m\) уменьшает систематическое завышение/занижение.

### 3.3 Small-range correction (LinearCounting)
Для малых кардинальностей (обычно когда оценка \(E \le 2.5m\)) применяется LinearCounting.  
Эта коррекция улучшает точность на ранних шагах, когда ещё много нулевых регистров.

В нашем случае на начальных t значения также показывают адекватное поведение и не выбиваются из ожидаемой относительной погрешности.

---

## 4) Дополнительное замечание: смещение (bias)

По данным `graph1.csv` и `graph2.csv` средняя оценка `mean_est` на большинстве шагов слегка **занижает** истинное значение (обычно на ~0.6–1.6%).  
Небольшое смещение возможно из-за конечных размеров потоков, особенностей хеширования и переходных режимов. При этом основная характеристика (разброс/RSE) соответствует теории.

---

## Итог

Для параметра **B = 9 (m = 512)**:

- практическая относительная ошибка \(\widehat{RSE}\) близка к теоретической \(1.04/\sqrt{m}\),
- значения укладываются в консервативную границу \(1.32/\sqrt{m}\),
- оценка стабильна: относительная дисперсия держится около 4–5%,
- выбранные константы (αm, LinearCounting) обеспечивают корректную работу алгоритма в разных режимах потока.

